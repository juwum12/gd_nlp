{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "03fb5525",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'C:/users/juwon/practice_aiffel/gd_nlp/seq2seq/'\n",
    "kor_path = data_path + 'korean-english-park.train.ko'\n",
    "eng_path = data_path + 'korean-english-park.train.en'\n",
    "\n",
    "def clean_corpsus(kor_path, en_path):\n",
    "    with open(kor_path, 'r', encoding ='UTF-8') as f : kor = f.read().splitlines()\n",
    "    with open(eng_path, 'r', encoding ='UTF-8') as f : eng = f.read().splitlines()\n",
    "    \n",
    "    return kor, eng\n",
    "\n",
    "kor , eng = clean_corpsus(kor_path, eng_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "784b62bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"</td>\n",
       "      <td>Much of personal computing is about \"can you t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
       "      <td>so a mention a few weeks ago about a rechargea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다.</td>\n",
       "      <td>Like all optical mice, But it also doesn't nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...</td>\n",
       "      <td>uses gyroscopic sensors to control the cursor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...</td>\n",
       "      <td>Intelligence officials have revealed a spate o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94118</th>\n",
       "      <td>“우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...</td>\n",
       "      <td>””We are hoping to seize material evidence to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94119</th>\n",
       "      <td>월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다.</td>\n",
       "      <td>” On Monday, police secured statements from si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94120</th>\n",
       "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다.</td>\n",
       "      <td>But the lack of material evidence is making it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94121</th>\n",
       "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.</td>\n",
       "      <td>Kim and his son both deny the allegations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94122</th>\n",
       "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
       "      <td>Police are planning to seek arrest warrants fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94123 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ko  \\\n",
       "0                   개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"   \n",
       "1      모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
       "2                             그러나 이것은 또한 책상도 필요로 하지 않는다.   \n",
       "3      79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...   \n",
       "4      정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...   \n",
       "...                                                  ...   \n",
       "94118  “우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...   \n",
       "94119   월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다.   \n",
       "94120                       그러나 불충분한 증거 확보로 수사에 어려움이 있다.   \n",
       "94121                  김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.   \n",
       "94122  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
       "\n",
       "                                                      en  \n",
       "0      Much of personal computing is about \"can you t...  \n",
       "1      so a mention a few weeks ago about a rechargea...  \n",
       "2      Like all optical mice, But it also doesn't nee...  \n",
       "3      uses gyroscopic sensors to control the cursor ...  \n",
       "4      Intelligence officials have revealed a spate o...  \n",
       "...                                                  ...  \n",
       "94118  ””We are hoping to seize material evidence to ...  \n",
       "94119  ” On Monday, police secured statements from si...  \n",
       "94120  But the lack of material evidence is making it...  \n",
       "94121         Kim and his son both deny the allegations.  \n",
       "94122  Police are planning to seek arrest warrants fo...  \n",
       "\n",
       "[94123 rows x 2 columns]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({'ko':kor, 'en': eng})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "ba784c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop_duplicates(inplace = True, ignore_index = True)\n",
    "data.dropna(how='any',axis =0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e725fb2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ko</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"</td>\n",
       "      <td>Much of personal computing is about \"can you t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...</td>\n",
       "      <td>so a mention a few weeks ago about a rechargea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>그러나 이것은 또한 책상도 필요로 하지 않는다.</td>\n",
       "      <td>Like all optical mice, But it also doesn't nee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...</td>\n",
       "      <td>uses gyroscopic sensors to control the cursor ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...</td>\n",
       "      <td>Intelligence officials have revealed a spate o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78963</th>\n",
       "      <td>“우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...</td>\n",
       "      <td>””We are hoping to seize material evidence to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78964</th>\n",
       "      <td>월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다.</td>\n",
       "      <td>” On Monday, police secured statements from si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78965</th>\n",
       "      <td>그러나 불충분한 증거 확보로 수사에 어려움이 있다.</td>\n",
       "      <td>But the lack of material evidence is making it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78966</th>\n",
       "      <td>김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.</td>\n",
       "      <td>Kim and his son both deny the allegations.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78967</th>\n",
       "      <td>경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...</td>\n",
       "      <td>Police are planning to seek arrest warrants fo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>78968 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      ko  \\\n",
       "0                   개인용 컴퓨터 사용의 상당 부분은 \"이것보다 뛰어날 수 있느냐?\"   \n",
       "1      모든 광마우스와 마찬가지 로 이 광마우스도 책상 위에 놓는 마우스 패드를 필요로 하...   \n",
       "2                             그러나 이것은 또한 책상도 필요로 하지 않는다.   \n",
       "3      79.95달러하는 이 최첨단 무선 광마우스는 허공에서 팔목, 팔, 그외에 어떤 부분...   \n",
       "4      정보 관리들은 동남 아시아에서의 선박들에 대한 많은 (테러) 계획들이 실패로 돌아갔...   \n",
       "...                                                  ...   \n",
       "78963  “우리는 3월 8일 김승연 회장과 그의 아들이 보복폭행에 가담한 혐의를 찾기 위해 ...   \n",
       "78964   월요일 술집 종업원 6명은 김회장과 아들에게 폭행을 당했음을 진술했다고 경찰은 말했다.   \n",
       "78965                       그러나 불충분한 증거 확보로 수사에 어려움이 있다.   \n",
       "78966                  김회장과 그의 아들은 보복폭행 혐의를 강력히 부인하고 있다.   \n",
       "78967  경찰은 김회장의 집무실에서 추가 증거를 찾은 이후 가능한 한 오늘 김회장과 아들을 ...   \n",
       "\n",
       "                                                      en  \n",
       "0      Much of personal computing is about \"can you t...  \n",
       "1      so a mention a few weeks ago about a rechargea...  \n",
       "2      Like all optical mice, But it also doesn't nee...  \n",
       "3      uses gyroscopic sensors to control the cursor ...  \n",
       "4      Intelligence officials have revealed a spate o...  \n",
       "...                                                  ...  \n",
       "78963  ””We are hoping to seize material evidence to ...  \n",
       "78964  ” On Monday, police secured statements from si...  \n",
       "78965  But the lack of material evidence is making it...  \n",
       "78966         Kim and his son both deny the allegations.  \n",
       "78967  Police are planning to seek arrest warrants fo...  \n",
       "\n",
       "[78968 rows x 2 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "154d8225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocessing_sentence(sentence):\n",
    "    sentence = sentence.lower()\n",
    "    sentence = re.sub(r'\\'+', '\\'', sentence)\n",
    "    sentence = re.sub(r'\\\"+', '\\\"', sentence )\n",
    "    sentence = re.sub(r'\\([^)]*\\)', r'', sentence) # 괄호안 단어 삭제\n",
    "    sentence = re.sub(r'[^a-zA-Z가-힣.,?!\\'\\\"]', r' ', sentence)\n",
    "    sentence = re.sub(r'([.,?!\\'\\\"])', r' \\1 ', sentence)\n",
    "    sentence = re.sub(r'[ ]+', r' ', sentence)\n",
    "    sentence = sentence.strip()\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bacd6d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'on monday , police secured statements from six victims who said they were beaten directly by kim and his son .'"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_sentence(data['en'].loc[78964])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "14a67b32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77554\n",
      "77554\n"
     ]
    }
   ],
   "source": [
    "kor= []\n",
    "eng = []\n",
    "for i, sen in enumerate(data['ko']):\n",
    "    if len(sen) > 15:\n",
    "        kor.append(preprocessing_sentence(sen))\n",
    "        eng.append(preprocessing_sentence(data['en'].loc[i]))\n",
    "print(len(kor))\n",
    "print(len(eng))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6799a5e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sentencepiece as spm\n",
    "\n",
    "data_path = 'C:/users/juwon/practice_aiffel/gd_nlp/transformer/'\n",
    "\n",
    "def generate_tokenizer(corpus, \n",
    "                       vocab_size, \n",
    "                       lang='dsf',\n",
    "                       pad_id=0,\n",
    "                        bos_id=1,\n",
    "                        eos_id=2,\n",
    "                        unk_id=3):\n",
    "    \n",
    "    temp_file = data_path + '{}.temp'.format(lang)\n",
    "    \n",
    "    with open(temp_file, 'w', encoding='UTF-8') as f :\n",
    "        for row in corpus:\n",
    "            f.write(row+'\\n')\n",
    "            \n",
    "    spm.SentencePieceTrainer.Train('--input={} --pad_id={} --bos_id={} --eos_id={} --unk_id={} --model_prefix={} --vocab_size={}'.format(temp_file, pad_id, bos_id, eos_id, unk_id, lang, vocab_size))\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load('{}.model'.format(lang))\n",
    "    \n",
    "    return s\n",
    "\n",
    "kor_vocab_size = eng_vocab_size = 20000\n",
    "ko_tokenizer = generate_tokenizer(kor, kor_vocab_size, 'ko')\n",
    "en_tokenizer= generate_tokenizer(eng, eng_vocab_size, 'en')\n",
    "en_tokenizer.set_encode_extra_options('bos:eos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ec7a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "src_corpus = []\n",
    "tgt_corpus = []\n",
    "\n",
    "for i, sen in enumerate(kor):\n",
    "    kor_sen = ko_tokenizer.EncodeAsIds(sen)\n",
    "    eng_sen = en_tokenizer.EncodeAsIds(eng[i])\n",
    "    if (len(kor_sen)< 50) & (len(eng_sen) < 50) :\n",
    "        src_corpus.append(kor_sen)\n",
    "        tgt_corpus.append(eng_sen)\n",
    "src_corpus = random.sample(src_corpus, 30000)\n",
    "tgt_corpus = random.sample(tgt_corpus, 30000)\n",
    "        \n",
    "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "58f101e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def positional_encoding(pos, d_model):\n",
    "    table = np.zeros((pos, d_model))\n",
    "    for i in range(pos): \n",
    "        for j in range(d_model):\n",
    "            table[i][j] = i / np.power(10000, (2 *(j//2) / d_model))\n",
    "    sinusoid_table = table       \n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "2e5deedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.d_model =d_model\n",
    "        self.n_heads = n_heads\n",
    "        self.depth = d_model // self.n_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "    \n",
    "    def scaled_dot_product(self, q, k, v, mask):\n",
    "        d_k = tf.cast(k.shape[-1], tf.float32)\n",
    "        \n",
    "        qk = tf.matmul(q, k, transpose_b = True)\n",
    "        scaled_qk = qk / tf.math.sqrt(d_k)\n",
    "        \n",
    "        if mask is not None: scaled_qk += (mask * -1e9) \n",
    "\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis = -1)\n",
    "        out = tf.matmul(attentions, v)\n",
    "        \n",
    "        return out, attentions\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        split_x = tf.reshape(x, (batch_size, -1 , self.n_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm =[0,2,1,3])\n",
    "        \n",
    "        return split_x\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0,2,1,3])\n",
    "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
    "        \n",
    "        return combined_x\n",
    "    \n",
    "    def call(self, q, k, v ,mask):\n",
    "        wq = self.W_q(q)\n",
    "        wk = self.W_k(k)\n",
    "        wv = self.W_v(v)\n",
    "        \n",
    "        wq_splits = self.split_heads(wq)\n",
    "        wk_splits = self.split_heads(wk)\n",
    "        wv_splits = self.split_heads(wv)\n",
    "        \n",
    "        out, attentions = self.scaled_dot_product(wq_splits, wk_splits, wv_splits, mask)\n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, attentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "0d0dda5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3ce011",
   "metadata": {},
   "source": [
    "## Encoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1f1bad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        \n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        \n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6) \n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        \n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(x, mask):\n",
    "        # Multi Head Attention\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        # Positionwise Feed Forward Network \n",
    "        residual = out \n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8975d9",
   "metadata": {},
   "source": [
    "## Decoder Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "82dee93c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        \n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        \n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        \n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon = 1e-6)\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        # Masked MultiHead attention\n",
    "        residual = x \n",
    "        out = self.norm_1(x)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        # Multi Head Attention\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out, enc_dec_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        # Positionwise Feed Forward Network\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.dropout(out)\n",
    "        out += residual\n",
    "        \n",
    "        return out, dec_attn, enc_dec_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d42b63b",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "c9805f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self,\n",
    "                 n_layers,\n",
    "                 d_model,\n",
    "                 n_heads,\n",
    "                 d_ff,\n",
    "                 dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "    \n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "        \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9272e7b8",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "7857704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "    \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        \n",
    "        for i in range(self.n_layers):\n",
    "            out , dec_attn, dec_enc_attn = self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "            dec_attns.append(dec_attn)\n",
    "            enc_dec_attns.append(dec_enc_attn)\n",
    "        \n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67cb9977",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "62da72bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransFormer(tf.keras.Model):\n",
    "    def __init__(self, \n",
    "                 n_layers, \n",
    "                 d_model, \n",
    "                 n_heads, \n",
    "                 d_ff, \n",
    "                 src_vocab_size, \n",
    "                 tgt_vocab_size, \n",
    "                 pos_len,\n",
    "                 dropout, \n",
    "                 shared = True):\n",
    "        super(TransFormer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        \n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "        \n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        \n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "        \n",
    "        self.shared = shared\n",
    "        if shared : self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "            \n",
    "    def embedding(self, emb, x):\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "        if self.shared : out *= tf.math.sqrt(self.d_model)\n",
    "        \n",
    "        out += self.pos_encoding[np.newaxis,...][:, :seq_len, :]\n",
    "        out = self.dropout(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def call(self, enc_in ,dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "        \n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7f695",
   "metadata": {},
   "source": [
    "## masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "e6357521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "    \n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "    \n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a965e6a",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "bad5f6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warm_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warm_steps = warm_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warm_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
    "                                     beta_1 = 0.9,\n",
    "                                     beta_2 = 0.98,\n",
    "                                     epsilon = 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a23f04",
   "metadata": {},
   "source": [
    "## loss_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "34b5a17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction ='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    \n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_sum(loss_) / tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7fe206a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = TransFormer(n_layers=2,\n",
    "                         d_model = 512,\n",
    "                         n_heads = 8,\n",
    "                         d_ff = 2048,\n",
    "                         src_vocab_size=kor_vocab_size,\n",
    "                         tgt_vocab_size=eng_vocab_size,\n",
    "                         pos_len = 49,\n",
    "                         dropout = 0.3,\n",
    "                         shared=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b90b7b",
   "metadata": {},
   "source": [
    "## train step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ba031b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "    \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "    \n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "    \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizers.apply_gradients(zip(gradients,model.trainable.variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "4f8c4ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                          | 0/235 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\804274200.py\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file21qdgttt.py\", line 12, in tf__call\n        (enc_out, enc_attns) = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(enc_in), ag__.ld(enc_mask)), None, fscope)\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 27, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('out',), {'iterate_names': 'i'})\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 23, in loop_body\n        (out, enc_attn) = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(out), ag__.ld(mask)), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"trans_former_7\" \"                 f\"(type TransFormer).\n    \n    in user code:\n    \n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\1204890734.py\", line 43, in call  *\n            enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n        File \"C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 27, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('out',), {'iterate_names': 'i'})\n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 23, in loop_body\n            (out, enc_attn) = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(out), ag__.ld(mask)), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"encoder_7\" \"                 f\"(type Encoder).\n        \n        in user code:\n        \n            File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\3649841841.py\", line 17, in call  *\n                out, enc_attn = self.enc_layers[i](out, mask)\n        \n            TypeError: tf__call() takes 2 positional arguments but 3 were given\n        \n        \n        Call arguments received by layer \"encoder_7\" \"                 f\"(type Encoder):\n          • x=tf.Tensor(shape=(128, 49, 512), dtype=float32)\n          • mask=tf.Tensor(shape=(128, 1, 1, 49), dtype=float32)\n    \n    \n    Call arguments received by layer \"trans_former_7\" \"                 f\"(type TransFormer):\n      • enc_in=tf.Tensor(shape=(128, 49), dtype=int32)\n      • dec_in=tf.Tensor(shape=(128, 49), dtype=int32)\n      • enc_mask=tf.Tensor(shape=(128, 1, 1, 49), dtype=float32)\n      • causality_mask=tf.Tensor(shape=(128, 1, 49, 49), dtype=float32)\n      • dec_mask=tf.Tensor(shape=(128, 1, 49, 49), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17836\\3771311784.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         batch_loss, enc_attns, dec_attns, dec_enc_attns  = train_step(enc_train[idx:idx+BATCH_SIZE], \n\u001b[0m\u001b[0;32m     15\u001b[0m                                                                       \u001b[0mdec_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m                                                                       \u001b[0mtransformer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_fileqf2sjoya.py\u001b[0m in \u001b[0;36mtf__train_step\u001b[1;34m(src, tgt, model, optimizer)\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_enc_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_mask\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgenerate_masks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGradientTape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_enc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m                     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                 \u001b[0mgradients\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[1;31m# To get the full stack trace, call:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file21qdgttt.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask)\u001b[0m\n\u001b[0;32m     10\u001b[0m                 \u001b[0menc_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m                 \u001b[0mdec_in\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdec_emb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m                 \u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_attns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m                 \u001b[1;33m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_attns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdec_enc_attns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcausality_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdec_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\u001b[0m in \u001b[0;36mtf__call\u001b[1;34m(self, x, mask)\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0menc_attn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'enc_attn'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m                 \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfor_stmt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloop_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mget_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mset_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'out'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'iterate_names'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;34m'i'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\u001b[0m in \u001b[0;36mloop_body\u001b[1;34m(itr)\u001b[0m\n\u001b[0;32m     21\u001b[0m                     \u001b[1;32mnonlocal\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                     \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mitr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                     \u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menc_attn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc_layers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                     \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_attns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mld\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menc_attn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m                 \u001b[0mi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUndefined\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\804274200.py\", line 8, in train_step  *\n        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n    File \"C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file21qdgttt.py\", line 12, in tf__call\n        (enc_out, enc_attns) = ag__.converted_call(ag__.ld(self).encoder, (ag__.ld(enc_in), ag__.ld(enc_mask)), None, fscope)\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 27, in tf__call\n        ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('out',), {'iterate_names': 'i'})\n    File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 23, in loop_body\n        (out, enc_attn) = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(out), ag__.ld(mask)), None, fscope)\n\n    TypeError: Exception encountered when calling layer \"trans_former_7\" \"                 f\"(type TransFormer).\n    \n    in user code:\n    \n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\1204890734.py\", line 43, in call  *\n            enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n        File \"C:\\Users\\juwon\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 27, in tf__call\n            ag__.for_stmt(ag__.converted_call(ag__.ld(range), (ag__.ld(self).n_layers,), None, fscope), None, loop_body, get_state, set_state, ('out',), {'iterate_names': 'i'})\n        File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\__autograph_generated_file1mvswwdo.py\", line 23, in loop_body\n            (out, enc_attn) = ag__.converted_call(ag__.ld(self).enc_layers[ag__.ld(i)], (ag__.ld(out), ag__.ld(mask)), None, fscope)\n    \n        TypeError: Exception encountered when calling layer \"encoder_7\" \"                 f\"(type Encoder).\n        \n        in user code:\n        \n            File \"C:\\Users\\juwon\\AppData\\Local\\Temp\\ipykernel_17836\\3649841841.py\", line 17, in call  *\n                out, enc_attn = self.enc_layers[i](out, mask)\n        \n            TypeError: tf__call() takes 2 positional arguments but 3 were given\n        \n        \n        Call arguments received by layer \"encoder_7\" \"                 f\"(type Encoder):\n          • x=tf.Tensor(shape=(128, 49, 512), dtype=float32)\n          • mask=tf.Tensor(shape=(128, 1, 1, 49), dtype=float32)\n    \n    \n    Call arguments received by layer \"trans_former_7\" \"                 f\"(type TransFormer):\n      • enc_in=tf.Tensor(shape=(128, 49), dtype=int32)\n      • dec_in=tf.Tensor(shape=(128, 49), dtype=int32)\n      • enc_mask=tf.Tensor(shape=(128, 1, 1, 49), dtype=float32)\n      • causality_mask=tf.Tensor(shape=(128, 1, 49, 49), dtype=float32)\n      • dec_mask=tf.Tensor(shape=(128, 1, 49, 49), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 10\n",
    "loss=[]\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0 \n",
    "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "    random.shuffle(idx_list)\n",
    "    t = tqdm(idx_list)\n",
    "    \n",
    "    for (batch, idx) in enumerate(t):\n",
    "        batch_loss, enc_attns, dec_attns, dec_enc_attns  = train_step(enc_train[idx:idx+BATCH_SIZE], \n",
    "                                                                      dec_train[idx:idx+BATCH_SIZE], \n",
    "                                                                      transformer, \n",
    "                                                                      optimizer)\n",
    "        \n",
    "        total_loss += batch_loss\n",
    "        loss.append((total_loss.numpy() / (batch+1)))\n",
    "        \n",
    "        t.set_description_str('Epoch %2d' % (epoch+1))\n",
    "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc9a2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
    "                                                           maxlen=enc_train.shape[-1],\n",
    "                                                           padding='post')\n",
    "    \n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
    "        generate_masks(_input, output)\n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
    "        model(_input, \n",
    "              output,\n",
    "              enc_padding_mask,\n",
    "              combined_mask,\n",
    "              dec_padding_mask)\n",
    "\n",
    "        predicted_id = \\\n",
    "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6623d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "            \"오바마는 대통령이다.\",\n",
    "            \"시민들은 도시 속에 산다.\",\n",
    "            \"커피는 필요 없다.\",\n",
    "            \"일곱 명의 사망자가 발생했다.\"\n",
    "]\n",
    "for example in examples :\n",
    "    translate(example, transformer, ko_tokenizer, en_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed48da98",
   "metadata": {},
   "source": [
    "에러의 원인을 찾지 못해서 나머지 코드만 작성하여 제출합니다. enc_in과 mask의 연산에서 오류가 나는 것 같은데 코드상에서 문제점을 못찾겠네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e4c061",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
